\newpage
\section{Theoretische Grundlagen}
\textcolor{red}{Quellen überall ergänzen} \\
Im folgenden Teil der Ausarbeitung werden die theoretischen Grundlagen, die zum Verständnis benötigt werden, erläutert.
Zunächst wird der Oberbegriff Deep Learning kurz erklärt und die dazugehörige Methode der Bildklassifizierung beschrieben. Darauf folgt das Natural Language Processing mit der Named Entity Recognition.

\subsection{OSMI-Index}

\textcolor{red}{Stichpunkte noch ausformulieren} \\

-Bewertungsinstrument, welches zur Bewertung von E-Commerce Webseiten im Hinblick auf
deren sensorische Gestaltung dient und Verbesserungspotentiale aufzeigt
Parameter die sich nach den Sinnen richten (Haptik, Olfaktorik, Akustik, Gustatorik,
Visualität) \\
-JE Sinn gibt es eine Tabelle die die Evaluierung hinsichtlich bestimmter Indikatoren
vereinfacht ermöglicht. \\
-Indikatoren Bsp je Sinn\\
\begin{itemize}
    \item Haptik: 3D-Bilder, Video, Endowment-Effekt, …
    \item Olfaktorik: Mentale Simulation von Düfte, Schlüsselbegriffe für Düfte
    \item Auditive: Töne/Musik, Sprecher/Stimme, Schlüsselbegriffe für Akustik, …
    \item Gustatorische: Mental Simulation des Schmeckens, Verwendung von
    Farbschemata, Produktoptio \& Oberflächen, …
    \item Visuelle: Farbgebung, dynamische Bilder, Oberfläche, …
\end{itemize}

-Gewichtung der Indikatoren wird im OSMI nicht vorgenommen, weil nicht zweifelsfrei zu
argumentieren welcher mehr oder weniger bewertet wird (bisher keine Forschungsarbeiten
dazu) \\
-Indikatoren werden einzeln bewertet \& letztendlich fünf Parameter zw. 0 \& 1 liegen vor.
Daraus ergibt sich Gesamt-Index (ohne Gewichtung, arithmetischer Durchschnitt) für jede
Webseite > auch zw. 0 \& 1 und ist dann der OSMI-Index \\
-Je näher der OSMI an einer 1, desto erfolgreicher spricht die Webseite die Sensorik an. Wert
nahe 0 erhält wichtige Elemente entsprechend nicht \& erfüllt die Indikatoren nicht \\
-BSP eines OSMI-Indexes: Bild einfügen aus der Masterarbeit mymuesli.de oder so



möglicher Aufbau:
1.	Bildklassifizierung
a.Datenset
b.Umsetzung
2.	NER
a.	Datenset
b.	Umsetzung
3.	Zusammenführung
4.	Consultingteil

\subsection{Deep Learning}

Die Image Classification ist ein Anwendungsfall für die Technik des Deep Learning.
Als Teilgebiet des Maschine Learning bedient sich das Deep Learning mehrschichtiger neuronaler Netze, welche auf Basis großer Datenmengen bereits Erlerntes mit neuen Inhalten verknüpft und somit wiederum erneut lernt. Deep Learning macht es möglich, dass die Maschine selbstständig die eignen Fähigkeiten verbessert.
Anwendungsbereiche für Deep Learning können beispielsweise die Gesichts-, Objekt- oder Spracherkennung sein. Die Anwendung der Objekterkennung wird nachfolgend beschrieben.

\subsubsection{Image Classification}
Bei der Image Classification handelt es sich um eine Technik, die ein Objekt auf dem Bild einer bestimmten Klasse oder einer wahrscheinlichen Klasse zuordnet. Als Ziel kann die genaue Identifizierung der Bildmerkmale verstanden werden.
Es gibt verschiedene Methoden, die zur Image Classification eingesetzt werden können wie die Supervised Classification, die Unsupervised Classification oder auch die Convolutional Neural Networks (CNN). Letzteres wird am häufigsten für den Anwendungsfall herangezogen.

\subsubsection{Convolutional Neural Network}
Das CNN ist eine besondere Form eines künstlichen neuronalen Netzes.
Es zeichnet sich durch mehrere Schichten wie den Convolutional- Layer, der Pooling Layer und der Fully-Connected Layer aus. Die Architektur ist in der Abbildung xy dargestellt.
\\
\textcolor{red}{Grafik einfügen} \\

In den Schichten der Convolution werden die Eingabebilder analysiert und Merkmale (z.Bsp.: Linien oder Kanten) der Bilder erkannt und extrahiert.
Die Verarbeitung dieser Merkmale erfolgt in Matrizen, die Feature Maps genannt werden. \\
Die Feature Maps als Ausgabe der Convolutional Layer werden darauf in den Pooling Layer eingegeben.
Die Größe der Bilder wird in dieser Schicht reduziert und durch Methoden wie dem Max-Pooling nur die wesentlichen Merkmale weitergegeben.
Alle anderen Informationen sind für die Verarbeitung überflüssig und werden verworfen.  Ergebnis dieser Schicht ist die gleiche Anzahl an Feature Maps, allerdings in komprimierter Form. \\
Der Fully-Connected Layer bildet den Abschluss der CNN-Architektur. Jeder Knoten in der Ausgabeschicht ist hier direkt mit einem Knoten der vorgelagerten Schicht verbunden.
Mithilfe einer Linearkombination und einer Aktivierungsfunktion wird schlussendlich das Bild klassifiziert. Schlussendlich wird dem Bild die Zugehörigkeit zu einer Klasse anhand einer Wahrscheinlichkeit ausgegeben.

\subsection{Natural Language Processing}
Die Named Entity Recognition ist eine Technik, welches dem Oberbegriff Natural Language Processing (NLP) zugeordnet wird. NLP beschäftigt sich mit der Verarbeitung und dem Verständnis der menschlichen Sprache durch einen Computer.
Ziel dieser Techniken ist es eine direkte Kommunikation zwischen dem Menschen und dem Computer mithilfe der Sprache herzustellen. Die Fachgebiete der Computerlinguistik, Informatik, Kognitionswissenschaft und künstlicher Intelligenz werden hier vereint.
Anwendungsfälle können beispielsweise die Extraktion der Bedeutung von Sätzen oder Satzteilen oder auch die Erkennung von Satzzusammenhängen sein.   Neben Techniken wie der Sentiment-Analyse und der Spracherkennung gehört auch die Named Entity Recognition zu den Funktionen des NLP.

\subsubsection{Named Entity Recognition}
Die Named Entity Recognition (NER) hat zur Aufgabe automatisiert Entitäten in einem Textdokument zu finden und zu klassifizieren. Letzteres geschieht anhand zuvor definierter Kategorien.
Eine Entität muss dabei nicht nur ein einzelnes Wort sein, sondern kann auch eine Reihe von Wörtern darstellen, solange sie sich auf dieselbe Sache beziehen.

\subsubsection{Vorgehen bei der NER}
In der NER-Technik werden zwei Schritte durchgeführt, um zu Ergebnissen zu gelangen:

\begin{enumerate}
    \item Erkennen einer Entität
    \item Kategorisierung der Entität
\end{enumerate}


Im ersten Schritt wird geprüft, ob eine Wortfolge eine Entität bildet. Die Anfangs- und Endgrenzen der Entitäten werden hierbei festgelegt. Der zweite Schritt hat zum Ziel die zuvor definierte Entität in eine der zuvor definierten Klassen einzuordnen.
Häufig verwendete Klassen sind beispielsweise Orte, Namen oder Organisationen, welche unter die generischen Kategorien fallen. Des Weiteren gibt es Domänenspezifische Kategorien (Proteine, Enzyme und Gene).
\\
Zur Durchführung der beiden Schritte gibt es verschiedene Ansätze, die angewendet werden können. Ausgehend von den annotierten Datensätzen, die beispielsweise aufgrund von manuell erstellten Regeln oder auf Basis von Kontextähnlichkeiten generiert werden, werden Modelle mithilfe von Machine Learning entwickelt.
Für zuvor ungesehene Daten ermitteln die Modelle Vorhersagemodelle zur Erkennung und Kategorisierung der Entitäten. Eine weitere Möglichkeit ist der Einsatz von Deep Learning zur NER. In diesem Ansatz können auch nicht-lineare Zusammenhänge erkannt und gelernt werden.
\\
Ein Beispiel für ein Textdokument, in dem die NER Technik angewendet wurde, ist in Abbildung xy dargestellt.\\
\textcolor{red}{Grafik einfügen} \\

Die NER-Technik kann in unterschiedlichen Bereichen angewendet werden. Zum Beispiel können durch die Anwendung die Antwortzeiten im Kundendienst verringert werden, indem die Anfragen zuvor kategorisiert oder direkt dem zuständigen Mitarbeiter zugeordnet werden.
\\
Um die Qualität der NER-Technik zu bewerten, werden die Kennzahlen Precision, Recall und der F-Score hinzugezogen.
Zur Ermittlung dieser muss zunächst die Anzahl der Entitäten mit verschiedenen Ausprägungen ermittelt werden (FP, FN, TP).

\begin{itemize}
    \item FP: Eine Entität wurde erkannt, obwohl sie keine darstellt
    \item FN: Eine Entität wurde nicht erkannt, obwohl sie eine darstellt
    \item TP: Eine Entität wurde richtig erkannt
\end{itemize}

Die Precision zeigt das Verhältnis zwischen richtig erkannten Entitäten und der Gesamtheit der identifizierten Entitäten an. Die Formel lautet wir folgt:
\begin{align}
    Precision {=} \frac{\ac{TP}}{(\ac{TP}+{\ac{FP}})}
\end{align}
Der Recall stellt den Anteil der richtig erkannten Entitäten an der Gesamtheit aller möglichen Entitäten dar.
\begin{flalign}
    Recall{} {=} {}\frac{\ac{TP}}{(\ac{TP}+{\ac{FN}})}
\end{flalign}
Der F-Score ist die Kennzahl, der die Preicision und den Recall zu einem harmonischen Mittel vereint:
\begin{flalign}
    F-Score{} {=} {}2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}
\end{flalign}
